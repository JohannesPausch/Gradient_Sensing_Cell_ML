# test of Neural Network training for Gradient Sensening of Cell
# sourcenum = 10
# receptornum = 10
# particlenum = varies (1st column), accuracy 2nd column, mlp score 3rd column
# recepsurface_ratio = 10
# distanceexact = 3
# radiusexact = 1
# diffusionexact = 1
# rateexact = 1
# receptor_seed = 1
# number of particle seeds particle_seed = 100
# first_layer of NN = 19
# second_layer of NN = 0
# my_max_iterations for mlp training = 5000
10	0.28444444444444444	0.3333333333333333
12	0.27555555555555555	0.36
14	0.2577777777777778	0.35555555555555557
16	0.32	0.3688888888888889
18	0.38222222222222224	0.41333333333333333
20	0.43555555555555553	0.4177777777777778
22	0.4311111111111111	0.4488888888888889
24	0.49777777777777776	0.4711111111111111
26	0.4888888888888889	0.4622222222222222
28	0.4666666666666667	0.4622222222222222
30	0.5111111111111111	0.43555555555555553
32	0.5155555555555555	0.4711111111111111
34	0.5333333333333333	0.48444444444444446
36	0.5066666666666667	0.5155555555555555
38	0.5288888888888889	0.49777777777777776
40	0.5333333333333333	0.5333333333333333
42	0.5555555555555556	0.5244444444444445
44	0.6	0.5866666666666667
46	0.5733333333333334	0.5777777777777777
48	0.6577777777777778	0.6222222222222222
50	0.6711111111111111	0.6222222222222222
52	0.6666666666666666	0.6488888888888888
54	0.7066666666666667	0.6933333333333334
56	0.7066666666666667	0.6977777777777778
58	0.6888888888888889	0.68
60	0.7288888888888889	0.6666666666666666
62	0.7155555555555555	0.6577777777777778
64	0.7244444444444444	0.6666666666666666
66	0.7244444444444444	0.6622222222222223
68	0.7422222222222222	0.6577777777777778
70	0.7644444444444445	0.6844444444444444
72	0.76	0.6444444444444445
74	0.7644444444444445	0.68
76	0.7733333333333333	0.7066666666666667
78	0.7777777777777778	0.7111111111111111
80	0.8	0.7022222222222222
82	0.8	0.7244444444444444
84	0.8355555555555556	0.7466666666666667
86	0.8088888888888889	0.7911111111111111
88	0.8044444444444444	0.7644444444444445
90	0.8088888888888889	0.7688888888888888
92	0.8	0.7422222222222222
94	0.8088888888888889	0.7777777777777778
96	0.8	0.7688888888888888
98	0.8044444444444444	0.7422222222222222
100	0.84	0.7688888888888888
102	0.8311111111111111	0.7777777777777778
104	0.84	0.7911111111111111
106	0.8355555555555556	0.7688888888888888
108	0.8444444444444444	0.7955555555555556
110	0.8577777777777778	0.8355555555555556
112	0.8622222222222222	0.84
114	0.88	0.8444444444444444
116	0.84	0.8222222222222222
118	0.8533333333333334	0.8488888888888889
120	0.8577777777777778	0.8533333333333334
122	0.8622222222222222	0.84
124	0.8844444444444445	0.8533333333333334
126	0.8711111111111111	0.8444444444444444
128	0.8711111111111111	0.8311111111111111
130	0.8755555555555555	0.8266666666666667
132	0.8933333333333333	0.84
134	0.9022222222222223	0.8488888888888889
136	0.8977777777777778	0.8711111111111111
138	0.9155555555555556	0.88
140	0.8977777777777778	0.8533333333333334
142	0.8888888888888888	0.8533333333333334
144	0.8977777777777778	0.8488888888888889
146	0.8977777777777778	0.8577777777777778
148	0.9111111111111111	0.8488888888888889
150	0.9066666666666666	0.8666666666666667
152	0.9111111111111111	0.8311111111111111
154	0.8933333333333333	0.8355555555555556
156	0.8977777777777778	0.8355555555555556
158	0.9066666666666666	0.8444444444444444
160	0.9111111111111111	0.8355555555555556
162	0.92	0.8355555555555556
164	0.9244444444444444	0.84
166	0.92	0.8488888888888889
168	0.9288888888888889	0.8311111111111111
170	0.9288888888888889	0.8488888888888889
172	0.9288888888888889	0.8355555555555556
174	0.9288888888888889	0.8533333333333334
176	0.9333333333333333	0.8533333333333334
178	0.9377777777777778	0.8355555555555556
180	0.9377777777777778	0.8622222222222222
182	0.9422222222222222	0.8888888888888888
184	0.9422222222222222	0.88
186	0.9466666666666667	0.8844444444444445
188	0.9466666666666667	0.8888888888888888
190	0.9466666666666667	0.8933333333333333
192	0.96	0.8444444444444444
194	0.9422222222222222	0.8888888888888888
196	0.9511111111111111	0.88
198	0.9466666666666667	0.8755555555555555
